Weights & Biases 初始化成功。
--- 0. 加载原始完整数据从: sub_ratings.csv ---
完整原始数据集加载: 50 用户 (max_id+1), 50 物品 (max_id+1)。
从 'test_row.csv' 提取测试数据并更新训练集...
  测试集针对用户 ID: 49 (来自 test_row.csv)
  从 'test_row.csv' 提取了 27 个测试样本。
  更新后的 original_train_df 用于生成稀疏训练数据。
模型将基于原始数据维度初始化: 用户数=50, 物品数=50
测试数据集初始化: 27 个有效评分。
测试集创建成功，包含 27 个样本。
======= 主动学习迭代轮次: 1/10 (策略: Random) =======
--- Iter 1: 准备数据 ---
  生成初始稀疏训练数据...
初始稀疏训练数据已生成: 327 个评分。
  当前训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 1: 初始化/重置模型 ---
--- Iter 1: 训练模型 ---
--- 开始训练迭代轮次 1 (共 10 epochs) ---
  Iter 1 Epoch [1/10], Avg Train Loss: 18.109163
  Iter 1 Epoch [2/10], Avg Train Loss: 18.041686
  Iter 1 Epoch [3/10], Avg Train Loss: 17.936931
  Iter 1 Epoch [4/10], Avg Train Loss: 17.744118
  Iter 1 Epoch [5/10], Avg Train Loss: 17.418456
  Iter 1 Epoch [5/10], Test Loss: 18.172726
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_1\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_1\checkpoint_epoch_5_grads.pkl (包含 327 条记录)
  Iter 1 Epoch [6/10], Avg Train Loss: 16.907390
  Iter 1 Epoch [7/10], Avg Train Loss: 16.182206
  Iter 1 Epoch [8/10], Avg Train Loss: 15.217043
  Iter 1 Epoch [9/10], Avg Train Loss: 13.997771
  Iter 1 Epoch [10/10], Avg Train Loss: 12.566095
  Iter 1 Epoch [10/10], Test Loss: 13.985583
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_1\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_1\checkpoint_epoch_10_grads.pkl (包含 327 条记录)
--- 训练迭代轮次 1 完成 ---
--- Iter 1: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 1: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 41, 物品 21
    用户 7, 物品 18
    用户 27, 物品 10
    用户 46, 物品 46
    用户 16, 物品 32
    ...
--- Iter 1: 模拟数据采集 ---
  Iter 1: 已为 42 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 1: 迭代结束时最终测试损失: 13.985583
--- Iter 1: 生成可视化图像 ---
Iter 1 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_1_collection.png
======= 主动学习迭代轮次: 2/10 (策略: Random) =======
--- Iter 2: 准备数据 ---
  将上一轮收集的 42 个评分添加到训练数据...
已添加 42 个新评分到训练数据。总评分数: 369
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 2: 初始化/重置模型 ---
--- Iter 2: 训练模型 ---
--- 开始训练迭代轮次 2 (共 10 epochs) ---
  Iter 2 Epoch [1/10], Avg Train Loss: 17.806314
  Iter 2 Epoch [2/10], Avg Train Loss: 17.733909
  Iter 2 Epoch [3/10], Avg Train Loss: 17.603206
  Iter 2 Epoch [4/10], Avg Train Loss: 17.333467
  Iter 2 Epoch [5/10], Avg Train Loss: 16.831304
  Iter 2 Epoch [5/10], Test Loss: 17.664827
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_2\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_2\checkpoint_epoch_5_grads.pkl (包含 369 条记录)
  Iter 2 Epoch [6/10], Avg Train Loss: 16.025646
  Iter 2 Epoch [7/10], Avg Train Loss: 14.839681
  Iter 2 Epoch [8/10], Avg Train Loss: 13.291498
  Iter 2 Epoch [9/10], Avg Train Loss: 11.445077
  Iter 2 Epoch [10/10], Avg Train Loss: 9.367367
  Iter 2 Epoch [10/10], Test Loss: 9.901648
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_2\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_2\checkpoint_epoch_10_grads.pkl (包含 369 条记录)
--- 训练迭代轮次 2 完成 ---
--- Iter 2: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 2: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 27, 物品 22
    用户 27, 物品 26
    用户 29, 物品 46
    用户 3, 物品 43
    用户 41, 物品 41
    ...
--- Iter 2: 模拟数据采集 ---
  Iter 2: 已为 43 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 2: 迭代结束时最终测试损失: 9.901648
--- Iter 2: 生成可视化图像 ---
Iter 2 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_2_collection.png
======= 主动学习迭代轮次: 3/10 (策略: Random) =======
--- Iter 3: 准备数据 ---
  将上一轮收集的 43 个评分添加到训练数据...
已添加 43 个新评分到训练数据。总评分数: 412
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 3: 初始化/重置模型 ---
--- Iter 3: 训练模型 ---
--- 开始训练迭代轮次 3 (共 10 epochs) ---
  Iter 3 Epoch [1/10], Avg Train Loss: 17.840992
  Iter 3 Epoch [2/10], Avg Train Loss: 17.770574
  Iter 3 Epoch [3/10], Avg Train Loss: 17.644027
  Iter 3 Epoch [4/10], Avg Train Loss: 17.384556
  Iter 3 Epoch [5/10], Avg Train Loss: 16.908670
  Iter 3 Epoch [5/10], Test Loss: 17.757154
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_3\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_3\checkpoint_epoch_5_grads.pkl (包含 412 条记录)
  Iter 3 Epoch [6/10], Avg Train Loss: 16.128057
  Iter 3 Epoch [7/10], Avg Train Loss: 14.986956
  Iter 3 Epoch [8/10], Avg Train Loss: 13.480201
  Iter 3 Epoch [9/10], Avg Train Loss: 11.632007
  Iter 3 Epoch [10/10], Avg Train Loss: 9.565842
  Iter 3 Epoch [10/10], Test Loss: 10.456498
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_3\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_3\checkpoint_epoch_10_grads.pkl (包含 412 条记录)
--- 训练迭代轮次 3 完成 ---
--- Iter 3: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 3: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 36, 物品 6
    用户 4, 物品 34
    用户 13, 物品 32
    用户 16, 物品 8
    用户 22, 物品 4
    ...
--- Iter 3: 模拟数据采集 ---
  Iter 3: 已为 44 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 3: 迭代结束时最终测试损失: 10.456498
--- Iter 3: 生成可视化图像 ---
Iter 3 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_3_collection.png
======= 主动学习迭代轮次: 4/10 (策略: Random) =======
--- Iter 4: 准备数据 ---
  将上一轮收集的 44 个评分添加到训练数据...
已添加 44 个新评分到训练数据。总评分数: 456
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 4: 初始化/重置模型 ---
--- Iter 4: 训练模型 ---
--- 开始训练迭代轮次 4 (共 10 epochs) ---
  Iter 4 Epoch [1/10], Avg Train Loss: 17.852424
  Iter 4 Epoch [2/10], Avg Train Loss: 17.777845
  Iter 4 Epoch [3/10], Avg Train Loss: 17.640857
  Iter 4 Epoch [4/10], Avg Train Loss: 17.359164
  Iter 4 Epoch [5/10], Avg Train Loss: 16.841057
  Iter 4 Epoch [5/10], Test Loss: 17.770174
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_4\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_4\checkpoint_epoch_5_grads.pkl (包含 456 条记录)
  Iter 4 Epoch [6/10], Avg Train Loss: 15.999987
  Iter 4 Epoch [7/10], Avg Train Loss: 14.772509
  Iter 4 Epoch [8/10], Avg Train Loss: 13.149286
  Iter 4 Epoch [9/10], Avg Train Loss: 11.194779
  Iter 4 Epoch [10/10], Avg Train Loss: 9.015884
  Iter 4 Epoch [10/10], Test Loss: 9.283964
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_4\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_4\checkpoint_epoch_10_grads.pkl (包含 456 条记录)
--- 训练迭代轮次 4 完成 ---
--- Iter 4: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 4: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 1, 物品 42
    用户 21, 物品 17
    用户 4, 物品 49
    用户 17, 物品 22
    用户 41, 物品 32
    ...
--- Iter 4: 模拟数据采集 ---
  Iter 4: 已为 44 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 4: 迭代结束时最终测试损失: 9.283964
--- Iter 4: 生成可视化图像 ---
Iter 4 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_4_collection.png
======= 主动学习迭代轮次: 5/10 (策略: Random) =======
--- Iter 5: 准备数据 ---
  将上一轮收集的 44 个评分添加到训练数据...
已添加 44 个新评分到训练数据。总评分数: 500
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 5: 初始化/重置模型 ---
--- Iter 5: 训练模型 ---
--- 开始训练迭代轮次 5 (共 10 epochs) ---
  Iter 5 Epoch [1/10], Avg Train Loss: 18.033692
  Iter 5 Epoch [2/10], Avg Train Loss: 17.942519
  Iter 5 Epoch [3/10], Avg Train Loss: 17.725691
  Iter 5 Epoch [4/10], Avg Train Loss: 17.207955
  Iter 5 Epoch [5/10], Avg Train Loss: 16.206167
  Iter 5 Epoch [5/10], Test Loss: 16.448004
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_5\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_5\checkpoint_epoch_5_grads.pkl (包含 500 条记录)
  Iter 5 Epoch [6/10], Avg Train Loss: 14.587494
  Iter 5 Epoch [7/10], Avg Train Loss: 12.368045
  Iter 5 Epoch [8/10], Avg Train Loss: 9.754986
  Iter 5 Epoch [9/10], Avg Train Loss: 6.990283
  Iter 5 Epoch [10/10], Avg Train Loss: 4.536626
  Iter 5 Epoch [10/10], Test Loss: 3.605928
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_5\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_5\checkpoint_epoch_10_grads.pkl (包含 500 条记录)
--- 训练迭代轮次 5 完成 ---
--- Iter 5: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 5: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 4, 物品 29
    用户 24, 物品 31
    用户 9, 物品 41
    用户 44, 物品 0
    用户 48, 物品 49
    ...
--- Iter 5: 模拟数据采集 ---
  Iter 5: 已为 46 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 5: 迭代结束时最终测试损失: 3.605928
--- Iter 5: 生成可视化图像 ---
Iter 5 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_5_collection.png
======= 主动学习迭代轮次: 6/10 (策略: Random) =======
--- Iter 6: 准备数据 ---
  将上一轮收集的 46 个评分添加到训练数据...
已添加 46 个新评分到训练数据。总评分数: 546
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 6: 初始化/重置模型 ---
--- Iter 6: 训练模型 ---
--- 开始训练迭代轮次 6 (共 10 epochs) ---
  Iter 6 Epoch [1/10], Avg Train Loss: 17.863708
  Iter 6 Epoch [2/10], Avg Train Loss: 17.790941
  Iter 6 Epoch [3/10], Avg Train Loss: 17.620402
  Iter 6 Epoch [4/10], Avg Train Loss: 17.196522
  Iter 6 Epoch [5/10], Avg Train Loss: 16.332153
  Iter 6 Epoch [5/10], Test Loss: 16.639395
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_6\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_6\checkpoint_epoch_5_grads.pkl (包含 546 条记录)
  Iter 6 Epoch [6/10], Avg Train Loss: 14.862385
  Iter 6 Epoch [7/10], Avg Train Loss: 12.733794
  Iter 6 Epoch [8/10], Avg Train Loss: 10.086005
  Iter 6 Epoch [9/10], Avg Train Loss: 7.203127
  Iter 6 Epoch [10/10], Avg Train Loss: 4.598266
  Iter 6 Epoch [10/10], Test Loss: 4.045263
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_6\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_6\checkpoint_epoch_10_grads.pkl (包含 546 条记录)
--- 训练迭代轮次 6 完成 ---
--- Iter 6: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 6: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 42, 物品 1
    用户 5, 物品 41
    用户 27, 物品 8
    用户 29, 物品 11
    用户 3, 物品 16
    ...
--- Iter 6: 模拟数据采集 ---
  Iter 6: 已为 46 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 6: 迭代结束时最终测试损失: 4.045263
--- Iter 6: 生成可视化图像 ---
Iter 6 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_6_collection.png
======= 主动学习迭代轮次: 7/10 (策略: Random) =======
--- Iter 7: 准备数据 ---
  将上一轮收集的 46 个评分添加到训练数据...
已添加 46 个新评分到训练数据。总评分数: 592
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 7: 初始化/重置模型 ---
--- Iter 7: 训练模型 ---
--- 开始训练迭代轮次 7 (共 10 epochs) ---
  Iter 7 Epoch [1/10], Avg Train Loss: 17.904901
  Iter 7 Epoch [2/10], Avg Train Loss: 17.814060
  Iter 7 Epoch [3/10], Avg Train Loss: 17.562687
  Iter 7 Epoch [4/10], Avg Train Loss: 16.872675
  Iter 7 Epoch [5/10], Avg Train Loss: 15.419556
  Iter 7 Epoch [5/10], Test Loss: 15.907254
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_7\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_7\checkpoint_epoch_5_grads.pkl (包含 592 条记录)
  Iter 7 Epoch [6/10], Avg Train Loss: 12.995888
  Iter 7 Epoch [7/10], Avg Train Loss: 9.795909
  Iter 7 Epoch [8/10], Avg Train Loss: 6.417418
  Iter 7 Epoch [9/10], Avg Train Loss: 3.568913
  Iter 7 Epoch [10/10], Avg Train Loss: 1.766889
  Iter 7 Epoch [10/10], Test Loss: 1.818924
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_7\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_7\checkpoint_epoch_10_grads.pkl (包含 592 条记录)
--- 训练迭代轮次 7 完成 ---
--- Iter 7: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 7: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 1, 物品 31
    用户 20, 物品 11
    用户 31, 物品 13
    用户 22, 物品 16
    用户 21, 物品 17
    ...
--- Iter 7: 模拟数据采集 ---
  Iter 7: 已为 44 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 7: 迭代结束时最终测试损失: 1.818924
--- Iter 7: 生成可视化图像 ---
Iter 7 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_7_collection.png
======= 主动学习迭代轮次: 8/10 (策略: Random) =======
--- Iter 8: 准备数据 ---
  将上一轮收集的 44 个评分添加到训练数据...
已添加 44 个新评分到训练数据。总评分数: 636
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 8: 初始化/重置模型 ---
--- Iter 8: 训练模型 ---
--- 开始训练迭代轮次 8 (共 10 epochs) ---
  Iter 8 Epoch [1/10], Avg Train Loss: 17.854774
  Iter 8 Epoch [2/10], Avg Train Loss: 17.752428
  Iter 8 Epoch [3/10], Avg Train Loss: 17.422928
  Iter 8 Epoch [4/10], Avg Train Loss: 16.517927
  Iter 8 Epoch [5/10], Avg Train Loss: 14.671282
  Iter 8 Epoch [5/10], Test Loss: 15.303722
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_8\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_8\checkpoint_epoch_5_grads.pkl (包含 636 条记录)
  Iter 8 Epoch [6/10], Avg Train Loss: 11.820521
  Iter 8 Epoch [7/10], Avg Train Loss: 8.269353
  Iter 8 Epoch [8/10], Avg Train Loss: 4.832422
  Iter 8 Epoch [9/10], Avg Train Loss: 2.387950
  Iter 8 Epoch [10/10], Avg Train Loss: 1.177148
  Iter 8 Epoch [10/10], Test Loss: 1.388157
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_8\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_8\checkpoint_epoch_10_grads.pkl (包含 636 条记录)
--- 训练迭代轮次 8 完成 ---
--- Iter 8: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 8: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 7, 物品 35
    用户 48, 物品 26
    用户 38, 物品 38
    用户 39, 物品 14
    用户 49, 物品 33
    ...
--- Iter 8: 模拟数据采集 ---
  Iter 8: 已为 43 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 8: 迭代结束时最终测试损失: 1.388157
--- Iter 8: 生成可视化图像 ---
Iter 8 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_8_collection.png
======= 主动学习迭代轮次: 9/10 (策略: Random) =======
--- Iter 9: 准备数据 ---
  将上一轮收集的 43 个评分添加到训练数据...
已添加 43 个新评分到训练数据。总评分数: 679
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 9: 初始化/重置模型 ---
--- Iter 9: 训练模型 ---
--- 开始训练迭代轮次 9 (共 10 epochs) ---
  Iter 9 Epoch [1/10], Avg Train Loss: 17.888672
  Iter 9 Epoch [2/10], Avg Train Loss: 17.759177
  Iter 9 Epoch [3/10], Avg Train Loss: 17.303962
  Iter 9 Epoch [4/10], Avg Train Loss: 16.084124
  Iter 9 Epoch [5/10], Avg Train Loss: 13.711463
  Iter 9 Epoch [5/10], Test Loss: 13.391855
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_9\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_9\checkpoint_epoch_5_grads.pkl (包含 679 条记录)
  Iter 9 Epoch [6/10], Avg Train Loss: 10.239826
  Iter 9 Epoch [7/10], Avg Train Loss: 6.349772
  Iter 9 Epoch [8/10], Avg Train Loss: 3.162810
  Iter 9 Epoch [9/10], Avg Train Loss: 1.403038
  Iter 9 Epoch [10/10], Avg Train Loss: 0.816467
  Iter 9 Epoch [10/10], Test Loss: 0.446983
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_9\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_9\checkpoint_epoch_10_grads.pkl (包含 679 条记录)
--- 训练迭代轮次 9 完成 ---
--- Iter 9: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 9: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 21, 物品 26
    用户 18, 物品 42
    用户 25, 物品 48
    用户 35, 物品 2
    用户 29, 物品 5
    ...
--- Iter 9: 模拟数据采集 ---
  Iter 9: 已为 41 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 9: 迭代结束时最终测试损失: 0.446983
--- Iter 9: 生成可视化图像 ---
Iter 9 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_9_collection.png
======= 主动学习迭代轮次: 10/10 (策略: Random) =======
--- Iter 10: 准备数据 ---
  将上一轮收集的 41 个评分添加到训练数据...
已添加 41 个新评分到训练数据。总评分数: 720
  更新后训练数据用户数 (基于0的最大ID+1): 50, 物品数 (基于0的最大ID+1): 50
--- Iter 10: 初始化/重置模型 ---
--- Iter 10: 训练模型 ---
--- 开始训练迭代轮次 10 (共 10 epochs) ---
  Iter 10 Epoch [1/10], Avg Train Loss: 17.928855
  Iter 10 Epoch [2/10], Avg Train Loss: 17.775030
  Iter 10 Epoch [3/10], Avg Train Loss: 17.199545
  Iter 10 Epoch [4/10], Avg Train Loss: 15.669300
  Iter 10 Epoch [5/10], Avg Train Loss: 12.855155
  Iter 10 Epoch [5/10], Test Loss: 12.083211
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_10\model_epoch_5.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_10\checkpoint_epoch_5_grads.pkl (包含 720 条记录)
  Iter 10 Epoch [6/10], Avg Train Loss: 8.978252
  Iter 10 Epoch [7/10], Avg Train Loss: 5.007217
  Iter 10 Epoch [8/10], Avg Train Loss: 2.250324
  Iter 10 Epoch [9/10], Avg Train Loss: 1.058185
  Iter 10 Epoch [10/10], Avg Train Loss: 0.729638
  Iter 10 Epoch [10/10], Test Loss: 0.422252
    已保存checkpoint: checkpoints_iter\strategy_Random\iter_10\model_epoch_10.pt
    已保存梯度日志: gradient_logs_iter\strategy_Random\iter_10\checkpoint_epoch_10_grads.pkl (包含 720 条记录)
--- 训练迭代轮次 10 完成 ---
--- Iter 10: 使用随机策略生成采集点 ---
  随机策略选择了 50 个采集点。
  Iter 10: 已识别出 50 个新的待采集位置 (目标: 50):
    用户 30, 物品 16
    用户 21, 物品 39
    用户 44, 物品 25
    用户 41, 物品 5
    用户 21, 物品 43
    ...
--- Iter 10: 模拟数据采集 ---
  Iter 10: 已为 43 个采集点获取了“真实”评分并准备添加到下一轮。
  Iter 10: 迭代结束时最终测试损失: 0.422252
--- Iter 10: 生成可视化图像 ---
Iter 10 (Random): 评分矩阵可视化已保存至: visualizations_iter\strategy_Random\rating_matrix_iter_10_collection.png
======= 主动学习所有 10 轮迭代完成 =======